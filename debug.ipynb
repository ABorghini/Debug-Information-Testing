{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WkiHyT9JwY_"
      },
      "source": [
        "# Homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBYu3CrSIgmG"
      },
      "source": [
        "## Import libraries and Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTg2X9maIdyV"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# process data\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import graphviz \n",
        "\n",
        "# counter class\n",
        "from collections import Counter\n",
        "\n",
        "# bag-of-words\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix, PrecisionRecallDisplay, accuracy_score, plot_roc_curve\n",
        "\n",
        "# dataset splitter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# models\n",
        "from sklearn import svm, tree\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "wY2ERKqVHyay",
        "outputId": "d502d64a-09fb-4b88-bfa8-8c2c4e208a8b"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"drive/My Drive/Homework_dataset\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10vEcoR5Ki1O"
      },
      "outputs": [],
      "source": [
        "dataset_file = \"mapping_traces_O0.csv\"\n",
        "\n",
        "# read_file = pd.read_csv(dataset_file, delimiter=\"\\t\")\n",
        "# df = pd.DataFrame(read_file, columns=[\"instructions\", \"source_line\", \"bug\"])\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYFjskStkiCf"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnC4YPe_xLS-"
      },
      "outputs": [],
      "source": [
        "class MyDataset():\n",
        "    def __init__(self, \n",
        "                 data_file:str, \n",
        "                 words_vocabulary:dict, \n",
        "                 max_lenght_instructions=27,\n",
        "                 max_lenght_source_lines=37,\n",
        "                 blind=False,\n",
        "                 vectorizer_name:str = \"MyBoW\") -> None:\n",
        "\n",
        "        self.data_file = data_file\n",
        "        self.words_vocabulary = words_vocabulary\n",
        "        self.max_lenght_instructions = max_lenght_instructions\n",
        "        self.max_lenght_source_lines = max_lenght_source_lines\n",
        "        self.blind = blind\n",
        "        self.vectorizer_name = vectorizer_name\n",
        "\n",
        "        self.instructions, self.source_lines, self.labels = self.__load_data__()\n",
        "\n",
        "        # create vectorized representation of the dataset\n",
        "        if self.vectorizer_name == \"MyBoW\":\n",
        "            self.X = self.__vectorize_data_MyBoW__()\n",
        "\n",
        "            print(\"\\nX shape: (\", len(self.X), \",\", len(self.X[0]), \")\")\n",
        "            if not self.blind:\n",
        "                print(\"labels shape: \", self.labels.shape)\n",
        "\n",
        "        elif self.vectorizer_name in [\"TfidfVectorizer\", \"CountVectorizer\", \"HashingVectorizer\"]:\n",
        "            self.data = []\n",
        "\n",
        "            for (ins, sl) in tqdm(zip(self.instructions, self.source_lines)):\n",
        "                self.data.append(ins + sl)\n",
        "\n",
        "            if self.vectorizer_name == \"TfidfVectorizer\":\n",
        "                self.vectorizer = TfidfVectorizer(min_df=200, ngram_range=(1,2))\n",
        "\n",
        "            elif self.vectorizer_name == \"CountVectorizer\":\n",
        "                self.vectorizer = CountVectorizer(min_df=200, ngram_range=(1,2))\n",
        "\n",
        "            elif self.vectorizer_name == \"HashingVectorizer\":\n",
        "                self.vectorizer = HashingVectorizer(decode_error=\"ignore\", n_features=2 ** 7, alternate_sign=False, ngram_range=(1,2))\n",
        "            \n",
        "            self.X = self.vectorizer.fit_transform(self.data)\n",
        "\n",
        "            print(\"\\nX shape: \", self.X.shape)\n",
        "            if not self.blind:\n",
        "                print(\"labels shape: \", self.labels.shape)\n",
        "\n",
        "        else:\n",
        "            print(\"Wrong bag-of-word. Choose from the following: \\\"MyBoW\\\" (default), \\\"TfidfVectorizer\\\", \\\"CountVectorizer\\\", \\\"HashingVectorizer\\\"\") \n",
        "\n",
        "        # split dataset into train and test\n",
        "        if not self.blind:\n",
        "            self.X_train, self.X_test, self.labels_train, self.labels_test = train_test_split(self.X, self.labels, test_size=0.2, random_state=0)\n",
        "        else:\n",
        "            self.X_test = self.X\n",
        "\n",
        "\n",
        "    def __load_data__(self):\n",
        "        reader = pd.read_csv(self.data_file, delimiter=\"\\t\")\n",
        "        df = pd.DataFrame(reader, columns=[\"instructions\", \"source_line\", \"bug\"])\n",
        "\n",
        "        if not self.blind:\n",
        "            labels = df.bug\n",
        "        else:\n",
        "            labels = []\n",
        "\n",
        "        return df.instructions, df.source_line, labels\n",
        "        \n",
        "\n",
        "    def __vectorize_data_MyBoW__(self):\n",
        "        X = []\n",
        "\n",
        "        for (ins, sl) in tqdm(zip(self.instructions, self.source_lines)):\n",
        "\n",
        "            instruction = ins.strip().split()\n",
        "            source_line = sl.strip().split()\n",
        "\n",
        "            temp_instructions = []\n",
        "            temp_source_lines = []\n",
        "\n",
        "            # take the index that corresponds to each word from the words vocabulary\n",
        "            for elem in instruction:\n",
        "                elem = elem.replace('\"', \"\")\n",
        "                if elem in self.words_vocabulary:\n",
        "                    temp_instructions.append(self.words_vocabulary[elem])\n",
        "                else:\n",
        "                    temp_instructions.append(self.words_vocabulary[\"<unk>\"])\n",
        "\n",
        "            for elem in source_line:\n",
        "                elem = elem.replace('\"', \"\")\n",
        "                if elem in self.words_vocabulary:\n",
        "                    temp_source_lines.append(self.words_vocabulary[elem])\n",
        "                else:\n",
        "                    temp_source_lines.append(self.words_vocabulary[\"<unk>\"])\n",
        "\n",
        "            # padding vectors\n",
        "            temp_instructions += [0]*(self.max_lenght_instructions - len(temp_instructions))\n",
        "            temp_source_lines += [0]*(self.max_lenght_source_lines - len(temp_source_lines))\n",
        "\n",
        "            # trunc vectors\n",
        "            temp_instructions = temp_instructions[:self.max_lenght_instructions]\n",
        "            temp_source_lines = temp_source_lines[:self.max_lenght_source_lines]\n",
        "\n",
        "            X.append(temp_instructions + temp_source_lines)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    # def compress(self, vector, lenght):\n",
        "    #     compressed_vector = []\n",
        "    #     div = len(vector)//lenght\n",
        "    #     init = 0\n",
        "\n",
        "    #     if div == 0:\n",
        "    #         compressed_vector += vector\n",
        "    #         compressed_vector += [0]*(lenght - len(vector))\n",
        "    #     else:\n",
        "    #         for i in range(lenght-1):\n",
        "    #             compressed_vector.append(np.mean(vector[init:init+div]))\n",
        "    #             init += div\n",
        "    #         if init <= len(vector):\n",
        "    #             compressed_vector.append(np.mean(vector[init:]))\n",
        "                \n",
        "    #     return compressed_vector\n",
        "\n",
        "    def dataset_info(self):\n",
        "        if self.vectorizer_name == \"MyBoW\":\n",
        "            print(\"\\nSize of training set: %d\" %len(self.X_train))\n",
        "            print(\"Size of test set: %d\" %len(self.X_test))\n",
        "\n",
        "            print('First training sample')\n",
        "            id = 0\n",
        "            print(\"    x_train_%d = %r\" %(id,self.X_train[id]))\n",
        "            print(\"    y_train_%d = %r\" %(id,list(self.labels_train)[id]))\n",
        "\n",
        "            print('First test sample')\n",
        "            id = 0\n",
        "            print(\"    x_test_%d = %r\" %(id,self.X_test[id]))\n",
        "            print(\"    y_test_%d = %r\\n\" %(id,list(self.labels_test)[id]))\n",
        "        else:\n",
        "            print(\"\\nSize of training set: \", self.X_train.shape)\n",
        "            print(\"Size of test set: \", self.X_test.shape)\n",
        "\n",
        "            print('First training sample')\n",
        "            id = 0\n",
        "            print(\"    x_train_%d = %r\" %(id,self.X_train[id].todense()))\n",
        "            print(\"    y_train_%d = %r\" %(id,list(self.labels_train)[id]))\n",
        "\n",
        "            print('First test sample')\n",
        "            id = 0\n",
        "            print(\"    x_test_%d = %r\" %(id,self.X_test[id].todense()))\n",
        "            print(\"    y_test_%d = %r\\n\" %(id,list(self.labels_test)[id]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feDKZmtPWSC6"
      },
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GzkDIXP6BIww",
        "outputId": "386589c4-6bd9-4843-9feb-468506979fd8"
      },
      "outputs": [],
      "source": [
        "# compute instructions and source_code average lenght\n",
        "# in order to find the better lenght for MyBoW vectors\n",
        "\n",
        "def average_len(dataset_file):\n",
        "    sum_instructions = 0\n",
        "    sum_source_lines = 0\n",
        "    list_len_instructions = []\n",
        "    list_len_source_lines = []\n",
        "\n",
        "    reader = pd.read_csv(dataset_file, delimiter=\"\\t\")\n",
        "    df = pd.DataFrame(reader, columns=[\"instructions\", \"source_line\", \"bug\"])\n",
        "\n",
        "    counter = Counter()\n",
        "\n",
        "    for (ins, sl) in tqdm(zip(df.instructions, df.source_line)):\n",
        "        ins = ins.strip().split()\n",
        "        s_l = sl.strip().split()\n",
        "\n",
        "        list_len_instructions.append(len(ins))\n",
        "        sum_instructions += len(ins)\n",
        "        \n",
        "        list_len_source_lines.append(len(s_l))\n",
        "        sum_source_lines += len(s_l)\n",
        "\n",
        "    len_instructions = int(sum_instructions/len(reader))\n",
        "    len_source_lines = int(sum_source_lines/len(reader))\n",
        "\n",
        "    print(\"\\nAverage len instructions: \", len_instructions)\n",
        "    print(\"Average len source lines: \", len_source_lines, \"\\n\")\n",
        "\n",
        "    return list_len_instructions, list_len_source_lines\n",
        "\n",
        "ins, s_l = average_len(dataset_file)\n",
        "\n",
        "plt.hist(s_l, bins = 100, range= (0, 100))\n",
        "#plt.savefig('histogram_zoom.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGZwvCkJqAS"
      },
      "source": [
        "### Words vocaulary for BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io2k66tPq8gT",
        "outputId": "65d91dd0-3860-4a8d-bfcf-eb59d881cde4"
      },
      "outputs": [],
      "source": [
        "def words_vocabulary(file_name, min_freq=100):\n",
        "    reader = pd.read_csv(file_name, delimiter=\"\\t\")\n",
        "    df = pd.DataFrame(reader, columns=[\"instructions\", \"source_line\", \"bug\"])\n",
        "\n",
        "    counter = Counter()\n",
        "\n",
        "    for (ins, sl) in tqdm(zip(df.instructions, df.source_line)):\n",
        "        instruction = ins.replace('\"', \"\").strip().split()\n",
        "        source_line = sl.replace('\"', \"\").strip().split()\n",
        "\n",
        "        for token in instruction:\n",
        "            counter[token] += 1\n",
        "\n",
        "        for token in source_line:\n",
        "            counter[token] += 1\n",
        "\n",
        "    counter = counter.most_common()\n",
        "\n",
        "    words_vocab = {}\n",
        "    for i, elem in enumerate(counter):\n",
        "        if elem[1]>=min_freq:\n",
        "            words_vocab.update({elem[0]:i+2})\n",
        "    \n",
        "    words_vocab.update({\"<pad>\":0})\n",
        "    words_vocab.update({\"<unk>\":1})\n",
        "\n",
        "    return words_vocab\n",
        "\n",
        "words_vocab = words_vocabulary(dataset_file)\n",
        "print(\"\\nlenght: \", len(words_vocab))\n",
        "print(\"\\nwords vocab: \", words_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8IGdT_Jugj"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4-pRaXYea_",
        "outputId": "bc4d0ed8-0c85-4c2d-963b-ba2b5a0e83a5"
      },
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "# bow = \"MyBoW\" (default), \"TfidfVectorizer\", \"CountVectorizer\", \"HashingVectorizer\"\n",
        "dataset = MyDataset(data_file = dataset_file, words_vocabulary = words_vocab, vectorizer_name = \"TfidfVectorizer\")\n",
        "\n",
        "# print dataset info\n",
        "dataset.dataset_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvaHHVlXsXZY"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGX3I5EEkn9j"
      },
      "source": [
        "### Choose model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0WmceHzkntC"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"tree\": tree.DecisionTreeClassifier(min_samples_split=12, random_state=0, class_weight=\"balanced\"),\n",
        "    \"forest\": RandomForestClassifier(n_estimators = 100, min_samples_split=10, n_jobs=-1, verbose=1, random_state=0, class_weight=\"balanced\"),\n",
        "    \"svm\": svm.SVC(max_iter = 10000),\n",
        "    \"linear-svm\": svm.LinearSVC(max_iter = 10000, random_state=0, class_weight = \"balanced\"),\n",
        "    \"gaussian\": GaussianNB(),\n",
        "    \"bernoulli\": BernoulliNB(),\n",
        "    \"multinomial\": MultinomialNB(alpha=0.1),\n",
        "    \"kneighbors\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
        "    \"logistic-regression\": LogisticRegression(max_iter=10000, verbose = 1, n_jobs = -1, random_state=0, class_weight=\"balanced\"),\n",
        "    \"perceptron\": Perceptron(early_stopping = True, verbose=3, max_iter=200, n_iter_no_change=5, random_state=0, class_weight=\"balanced\"),\n",
        "    \"mlp\": MLPClassifier(hidden_layer_sizes = (1), early_stopping = True, max_iter = 200, verbose=3, n_iter_no_change=5, random_state=0)\n",
        "}\n",
        "\n",
        "model_name = \"linear-svm\"\n",
        "model = models[model_name]\n",
        "model_name = model_name + \"_\" + dataset.vectorizer_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9DWii82EB8e"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCzPlMqIkLgq"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# scaler.fit(dataset.X_train.toarray())\n",
        "# data = scaler.transform(dataset.X_train.toarray())\n",
        "# print(data)\n",
        "# model.fit(data, dataset.labels_train)\n",
        "\n",
        "model.fit(dataset.X_train, dataset.labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U8IxVA4D9Xm"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU4-hzUGmjAS"
      },
      "outputs": [],
      "source": [
        "# make predictions of the test and print classification report\n",
        "y_pred = model.predict(dataset.X_test)\n",
        "\n",
        "cr = classification_report(dataset.labels_test, y_pred, labels=None, target_names = [\"correct\", \"bugged\"], output_dict=True)\n",
        "# print(classification_report(dataset.labels_train, y_pred, labels=None, target_names = [\"correct\", \"bugged\"], digits=4))\n",
        "\n",
        "df = pd.DataFrame(cr).transpose()\n",
        "print(df.to_latex())\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOYyUUN4m8SY"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (7,7)\n",
        "plot_confusion_matrix(model, dataset.X_test, dataset.labels_test, display_labels = [\"correct\", \"bugged\"], normalize=\"true\")\n",
        "\n",
        "path = \"images/cm_\" + model_name + \".png\"\n",
        "plt.savefig(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjeCMTyiE27O"
      },
      "outputs": [],
      "source": [
        "# tree plot\n",
        "\n",
        "# dot_data = tree.export_graphviz(model, out_file=None,  \n",
        "#                                 class_names=[\"correct\", \"incorrect\"],  \n",
        "#                                 filled=True, rounded=True,  \n",
        "#                                 special_characters=True)  \n",
        "# graph = graphviz.Source(dot_data)  \n",
        "# graph.render(\"my_tree\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNj8ygVnKo3y"
      },
      "outputs": [],
      "source": [
        "# roc curve\n",
        "y_score = model.predict_proba(dataset.X_test)\n",
        "\n",
        "svc_disp = plot_roc_curve(model, dataset.X_test, dataset.labels_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AsipkX7zKWo-",
        "outputId": "a45b1480-6fc5-4a00-8593-57f8d6145a50"
      },
      "outputs": [],
      "source": [
        "# total plot\n",
        "\n",
        "accuracy = {}\n",
        "times = {}\n",
        "for model in tqdm(models):\n",
        "    print(\"Model: \" + model)\n",
        "    m = models[model]\n",
        "    tick = time.time()\n",
        "    if model == \"gaussian\":\n",
        "        m.fit(dataset.X_train.toarray(), dataset.labels_train)\n",
        "        times[model] = time.time() - tick\n",
        "        pred = m.predict(dataset.X_test.toarray())\n",
        "        accuracy[model] = accuracy_score(dataset.labels_test, pred)\n",
        "    else:\n",
        "        m.fit(dataset.X_train, dataset.labels_train)\n",
        "        times[model] = time.time() - tick\n",
        "        pred = m.predict(dataset.X_test)\n",
        "        accuracy[model] = accuracy_score(dataset.labels_test, pred)\n",
        "\n",
        "def autolabel(rectangles):\n",
        "    \"\"\"attach some text vi autolabel on rectangles.\"\"\"\n",
        "    for rect in rectangles:\n",
        "        height = rect.get_height()\n",
        "        ax.text(\n",
        "            rect.get_x() + rect.get_width() / 2.0,\n",
        "            1.05 * height,\n",
        "            \"%.4f\" % height,\n",
        "            ha=\"center\",\n",
        "            va=\"bottom\",\n",
        "        )\n",
        "        plt.setp(plt.xticks(x_pos, keys)[1], rotation=45)\n",
        "\n",
        "keys = list(accuracy.keys())\n",
        "acc = list(accuracy.values())\n",
        "\n",
        "f, ax = plt.subplots(figsize=(18,5))\n",
        "bar_colors = [\"limegreen\", \"greenyellow\",\"gold\", \"orange\", \"coral\",\"hotpink\", \"violet\", \"darkviolet\", \"mediumblue\", \"deepskyblue\", \"turquoise\"]\n",
        "x_pos = [0,4,8,12,16,20,24,28,32, 36, 40]\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "rectangles = plt.bar(x_pos, acc, width=2, color = bar_colors)\n",
        "autolabel(rectangles)\n",
        "\n",
        "\n",
        "plt.savefig(\"images/accuracy_my\")\n",
        "\n",
        "f, ax = plt.subplots(figsize=(18,5))\n",
        "x_pos = [0,4,8,12,16,20,24,28,32, 36, 40]\n",
        "bar_colors = [\"limegreen\", \"greenyellow\",\"gold\", \"orange\", \"coral\",\"hotpink\", \"violet\", \"darkviolet\", \"mediumblue\", \"turquoise\"]\n",
        "t = list(times.values())\n",
        "rectangles = plt.bar(x_pos, t, width=2, color = bar_colors)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "autolabel(rectangles)\n",
        "plt.savefig(\"images/times_count_my\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UICK4IQD8Ld"
      },
      "outputs": [],
      "source": [
        "# precision recall plot\n",
        "PrecisionRecallDisplay.from_estimator(model, dataset.X_test, dataset.labels_test, name=model_name)\n",
        "\n",
        "\n",
        "path = \"images/pdr_\" + model_name + \".png\"\n",
        "plt.savefig(path)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeFZD1tD-1Ju"
      },
      "source": [
        "## Blind Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZucVesl-3nK"
      },
      "outputs": [],
      "source": [
        "blind_test_file = \"blind_test.csv\"\n",
        "\n",
        "# create the dataset \n",
        "blind_dataset = MyDataset(blind_test_file, words_vocabulary = words_vocab, bow = \"MyBoW\", blind = True)\n",
        "\n",
        "# predict the blind test\n",
        "y_pred_blind = model.predict(blind_dataset.X_test)\n",
        "\n",
        "\n",
        "# save prediction on file\n",
        "# with open(\"1834906.txt\", \"w+\") as f:\n",
        "#     for p in y_pred_blind:\n",
        "#         f.write(p + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Homework_1_1834906.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
